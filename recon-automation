#!/usr/bin/env bash

set -uo pipefail

### Global settings ###
domain=""
output_dir=""
pd_tools=("subfinder" "shuffledns" "alterx" "dnsx" "naabu" "httpx" "katana" "urlfinder")

### Functions ###

install_script_tools() {
    local missing_tools=()

    printf "\n[INF] Checking if required tools are installed...\n"

    for tool in "${pd_tools[@]}"; do
        command -v "$tool" &> /dev/null && printf "[INF] %s is already installed.\n" "$tool" || missing_tools+=("$tool")
    done

    [[ ${#missing_tools[@]} -eq 0 ]] && return 0
    (IFS=,;pdtm -i "${pd_tools[*]}" -igp)
    
    if [[ $? -eq 0 ]]; then
        printf "\n[INF] All required tools were installed.\n"
    else
        printf "[ERR] Failed to install required tools.\n\n"
        return 1
    fi
}

# Define domain and output directory if unspecified.
define_variables() {
    if [[ -z "$domain" ]]; then
        while true; do
            read -e -r -p "[!] Please specify a domain: " domain
            if [[ -z "$domain" ]]; then
                printf "[ERR] Domain cannot be empty.\n"
            elif [[ ! "$domain" =~ ^[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$ ]]; then
                printf "[ERR] Invalid domain syntax. Please enter a valid domain.\n"
            else
                break
            fi
        done
    else
        if [[ ! "$domain" =~ ^[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$ ]]; then
            printf "[ERR] Invalid domain provided via -d flag: %s\n" "$domain" >&2
            exit 1
        fi
        printf "[INF] Using domain: %s\n" "$domain"
    fi
    
    local strip_protocol="${domain#*://}"
    local strip_name="${strip_protocol#www.}"
    local clean_name="${strip_name%%/*}"
    
    # Default output_dir from domain name if not set
    if [[ -z "$output_dir" ]]; then
        output_dir="$clean_name"
    fi
    # Normalize: strip trailing slashes, resolve relative dots
    output_dir="${output_dir%/}"
    
    if [[ "$output_dir" == *..* ]]; then
    printf "[ERR] Output directory path must not contain '..': %s\n" "$output_dir" >&2
    exit 1
    fi

    if [[ ! -d "$output_dir" ]]; then
        mkdir -p "./$output_dir"
        printf "[INF] Created directory: $output_dir.\n"
    else
        printf "[INF] Using existing directory: $output_dir.\n"
    fi

    for tool in "${pd_tools[@]}"; do
        declare -g "${tool}_out=$output_dir/${tool}_${clean_name}.txt"
        declare -g "${tool}_out_json=$output_dir/${tool}_${clean_name}.json"
        declare -g "${tool}_sorted=$output_dir/sorted_${tool}_${clean_name}.txt"
        declare -g "${tool}_sorted_json=$output_dir/sorted_${tool}_${clean_name}.json"
    done

    declare -g "httpx_2ndrun_out_json=$output_dir/httpx_2ndrun_${clean_name}.json"
    declare -g "httpx_final_in=$output_dir/httpx_final_in.txt"
    declare -g "report_file=$output_dir/report.md"
}

check_before_run() {
    local tool_name="$1"
    local tool_out="$2" 

    if [[ -f "$tool_out" && -s "$tool_out" ]]; then
        echo -e "\n[WRN] $tool_name output already exists. File: $tool_out"
        read -e -r -p "[OPT] Skip $tool_name (s), Overwrite File (o), or Backup File (b)? [S/o/b]: " choice
        
        case "$choice" in
            [sS]*)
                printf "[INF] Skipping $tool_name step.\n"
                return 1
                ;;
            [oO]*)
                printf "[INF] Overwriting existing file...\n"
                return 0
                ;;
            [bB]*)
                local timestamp; timestamp=$(date +"%Y%m%d_%H%M")
                local backup_file="${tool_out}_${timestamp}.bak"
                mv "$tool_out" "$backup_file"
                printf "[INF] Moved existing results to: %s\n" "$backup_file"
                return 0
                ;;
            *) 
                printf "[ERR] Invalid option. Skipping %s step.\n" "$tool_name"
                return 1 
                ;;
        esac
    fi
    return 0
}

run_subfinder() {
    local subfinder_flags=(-d "$domain" -all -o "$subfinder_out" -silent)
    local config_file="${HOME}/.config/subfinder/provider-config.yaml"

    printf "\n[INF] Setting up Subfinder.\n"
    printf " [+] Discover subdomains for a given target domain.\n"
    printf "[INF] This tool will run a passive scan.\n"
    printf "[INF] It is recommended to add API keys to: %s\n" "$config_file"

    read -e -r -p "[OPT] Open config file in editor before running? [y/N]: " choice
    if [[ "$choice" =~ ^[yY]$ ]]; then
        "${EDITOR:-nano}" "$config_file"
    fi

    printf "\n####################################################################\n"
    printf "##################### Starting Subfinder ###########################\n"
    printf "####################################################################\n"

    subfinder "${subfinder_flags[@]}" &>/dev/null
    
    if [[ $? -eq 0 && -s "$subfinder_out" ]]; then
        local findings=$(wc -l <"$subfinder_out")
        printf "[INF] Subfinder done - $findings subdomains saved.\n"
    else
        printf "[WRN] Subfinder completed, but no information was returned."
        return 0
    fi
}

run_shuffledns() {
    local wordlist="${PWD}/wordlist.txt"
    local resolvers="${PWD}/resolvers.txt"
    local shuffledns_flags=(-d "$domain" -w "$wordlist" -r "$resolvers" -mode bruteforce -o "$shuffledns_out" -silent)

    printf "\n[INF] Setting up ShuffleDNS\n"
    printf " [+] Brute-force subdomains that may not be found through passive enumeration.\n"
    printf "[WRN] This tool runs a ACTIVE and NOISY scan.\n"
    printf "[!] Please select Confirm to continue\n"
    
    while true; do
    read -e -r -p "[OPT] Confirm (c) Skip step (s): " choice
        if [[ "$choice" =~ ^[cC]$ ]]; then
            break
        elif [[ "$choice" =~ ^[sS]$ ]]; then
           printf "[INF] Skipping ShuffleDNS.\n\n"
            return 0
       else
            printf "[ERR] Wrong option.\n"
           continue
        fi
    done

    printf "[INF] Shuffledns requires a list with public DNS resolvers and a bruteforcing wordlists for best results.\n"
    printf "      \n%s\n" "Recommended sources:"
    printf "   %s\n" "- Trickest  (Resolvers):  https://github.com/trickest/resolvers/blob/main/resolvers.txt"
    printf "   %s\n" "- SecLists  (Wordlists):  https://github.com/danielmiessler/SecLists"
    printf "   %s\n" "- AssetNote (Wordlists):  https://wordlists.assetnote.io"
    printf "\n[!] Download one and save it as resolvers.txt in your working directory.\n"
    printf "[!] Download one and save it as wordlist.txt in your working directory.\n\n"
    printf "[!] Please select Confirm to continue\n"
    
    while true; do
        read -e -r -p "[OPT] Confirm (c) Skip step (s): " add_choice
            if [[ "$add_choice" =~ ^[cC]$ ]]; then
                if [[ ! -f "$wordlist" || ! -f "$resolvers" ]]; then
                    printf "[ERR] Missing files! Ensure both wordlist.txt and resolvers.txt exist.\n"
                    continue
                else
                    break
                fi
            elif [[ "$add_choice" =~ ^[sS]$ ]]; then
                printf "[INF] Skipping step.\n"
                break
            else
                printf "[ERR] Wrong option.\n"
                continue
            fi
    done

    printf "\n###############################################################\n"
    printf "##################### Starting ShuffleDNS #####################\n"
    printf "###############################################################\n"

    shuffledns "${shuffledns_flags[@]}" &>/dev/null

    if [[ $? -eq 0 && -s "$shuffledns_out" ]]; then
        local findings=$(wc -l < "$shuffledns_out")
        printf "\n[INF] ShuffleDNS done - $findings subdomains saved.\n"
    else
        printf "[WRN] ShuffleDNS completed, but no information was returned."
        return 0
    fi
}

run_alterx() {
    local keywords_file="${PWD}/target-keywords.txt"
    local alterx_flags=("-silent" "-enrich" "-o" "$alterx_out")
    local file_input=""

    printf "\n[INF] Setting up AlterX\n"

    # Sort by uniqueness into a single file
    if [[ -s "$subfinder_out" && -s "$shuffledns_out" ]]; then
        sort -u "$subfinder_out" "$shuffledns_out" > "${output_dir}/sorted_subfinder_shuffledns.txt"
        file_input="${output_dir}/sorted_subfinder_shuffledns.txt"
    elif [[ -s "$subfinder_out" ]]; then
        printf "[WRN] ShuffleDNS results missing. Using Subfinder output only.\n"
        file_input="$subfinder_out"
    elif [[ -s "$shuffledns_out" ]]; then
        printf "[WRN] Subfinder results missing. Using ShuffleDNS output only.\n"
        file_input="$shuffledns_out"
    else
        printf "[ERR] No input files found for AlterX! Skipping.\n"
        return 1
    fi

    # Add target keywords
    printf "[INF] It is recommended to add target specific keywords to enhance results.\n"
    printf "[INF] : company products, acronyms, brands, language specific terms\n"
    printf "[!] Do you wish to add any?\n"
    
    while true; do
    read -e -r -p "[OPT] Add now (a) Skip action (s): " add_choice
    if [[ "$add_choice" =~ ^[aA]$ ]]; then
        while true; do
            printf "[!] create a file named target-keywords.txt containing a keyword per line.\n"
            read -e -r -p "[OPT] Continue (c) or Skip action (s): " loop_choice
            if [[ "$loop_choice" =~ ^[cC]$ ]]; then
                if [[ -s "$keywords_file" ]]; then
                    alterx_flags+=("-pp" "word=$keywords_file")
                    break
                else
                    printf "[ERR] File target-keywords.txt not found or empty.\n"
                fi
            elif [[ "$loop_choice" =~ ^[sS]$ ]]; then
                printf "[INF] Skipping action.\n"
                break
            else
                printf "[ERR] Wrong option.\n"
                continue
            fi
        done
        break
    elif [[ "$add_choice" =~ ^[sS]$ ]]; then
        printf "[INF] Skipping action.\n"
        break
    else
        printf "[ERR] Wrong option.\n"
        continue
    fi
    done

    # Run AlterX
    printf "\n###############################################################\n"
    printf "#####################   Starting Alterx   #####################\n"
    printf "###############################################################\n"
    printf "\n [+] Generate permutations of subdomains to identify additional assets\n"

    alterx "${alterx_flags[@]}" < "$file_input" &> /dev/null
    
    if [[ $? -eq 0 ]]; then
        local findings=$(wc -l < "$alterx_out")
        printf "\n[INF] AlterX done - $findings permutations saved.\n"
    else
        printf "[WRN] AlterX completed, but no information was returned.\n"
        return 0
    fi

    # Final sort to prevent duplications in big scopes
    sort -u "$alterx_out" > "$alterx_sorted" 
}

run_dnsx() {
    local dnsx_flags=(-l "$alterx_sorted" -silent -a -aaaa -cname -resp-only -json -r resolvers.txt)
    dnsx_flags+=( -t 150 -retry 3 -o "$dnsx_out_json")
    
    printf "\n###############################################################\n"
    printf "#####################    Starting dnsx    #####################\n"
    printf "###############################################################\n"
    printf "\n [+] Verify which subdomains resolve to valid hosts.\n"
    printf "[INF] This an ACTIVE and NOISY step.\n"

    printf "[!] Select Confirm to start.\n"
    
    while true; do
    read -e -r -p "[OPT] Confirm (c) Skip step (s): " choice
        if [[ "$choice" =~ ^[cC]$ ]]; then
            printf "\n[INF] Starting dnsx. This will take a while.\n"
            break
        elif [[ "$choice" =~ ^[sS]$ ]]; then
            printf "[INF] Skipping dnsx.\n\n"
            return 0
        else
            printf "[ERR] Wrong option.\n"
            continue
        fi
    done

    dnsx "${dnsx_flags[@]}" &> /dev/null

    if [[ $? -eq 0 && -s "$dnsx_out_json" ]]; then
        local resolved_hosts=$(jq -c 'select(.host != null and (.a + .aaaa + .cname | length > 0))' "$dnsx_out_json" 2>/dev/null | wc -l)
        local resolved_a_aaaa=$(jq -c 'select((.a | length > 0) or (.aaaa | length > 0))' "$dnsx_out_json" 2>/dev/null | wc -l)
        local resolved_cname=$(jq -c 'select(.cname | length > 0)' "$dnsx_out_json" 2>/dev/null | wc -l)
        local resolved_sample=$(head -n 200 "$dnsx_out_json" | jq -r '
        select(.host != null and (.a[0] != null or .aaaa[0] != null) and .cname[0] != null) | "\(.host)\t->\t\((.a[0] // .aaaa[0]))\t|\t\(.cname[0])"
        ' 2>/dev/null | head -n 5 | column -t -s $'\t' | sed 's/^/       /')

        printf "[INF] dnsx done - %s resolved hosts.\n" "$resolved_hosts"
        printf " [+] %s with A/AAAA records.\n" "$resolved_a_aaaa"
        printf " [+] %s with CNAME (potential takeovers?)\n" "$resolved_cname"
        printf "Sample: \n%s\n" "$resolved_sample"
    else
        printf "[WRN] dnsx completed, but no information was returned.\n"
        return 0
    fi

    # Create a cleartext sorted file for input
    jq -r 'select((.a | length > 0) or (.aaaa | length > 0) or (.cname | length > 0)) | .host' "$dnsx_out_json" 2>/dev/null | sort -u > "$dnsx_out_sorted"
}

# Run Naabu
run_naabu() {
    local naabu_flags=(-top-ports 1000 -rate 1000 -c 25 -warm-up-time 2 -retries 2 -timeout 3000 -exclude-cdn -sV -silent -stats)
    naabu_flags+=( -json -o "$naabu_out_json")
    
    printf "\n###############################################################\n"
    printf "#####################    Starting naabu    #####################\n"
    printf "###############################################################\n"
    printf "\n [+] Identify open ports on resolved hosts to find additional applications.\n"
    printf "[INF] This an ACTIVE and NOISY step.\n"

    printf "[!] Select Confirm to start.\n"
    
    while true; do
    read -e -r -p "[OPT] Confirm (c) Skip step (s): " choice
        if [[ "$choice" =~ ^[cC]$ ]]; then
            printf "\n[INF] Starting naabu. This will take a while.\n"
            break
        elif [[ "$choice" =~ ^[sS]$ ]]; then
            printf "[INF] Skipping Naabu.\n\n"
            return 0
        else
            printf "[ERR] Wrong option.\n"
            continue
        fi
    done

     naabu "${naabu_flags[@]}" < "$dnsx_out_sorted" &> /dev/null 

    if [[ $? -eq 0 && -s "$naabu_out_json" ]]; then
        local hosts=$(jq -r '.host' "$naabu_out_json" 2>/dev/null | sort -u | wc -l)
        local ports=$(jq -r '.port' "$naabu_out_json" 2>/dev/null | wc -l)
        local unique=$(jq -r '.port' "$naabu_out_json" 2>/dev/null | sort -u | wc -l)
        local top=$(jq -r '.port' "$naabu_out_json" 2>/dev/null | sort | uniq -c | sort -rn | head -3 | awk '{printf "%s (%s), ", $2, $1}')

        printf "[INF] Naabu done.\n"
        printf " [+] Hosts Processed: %s hosts\n" "$hosts"
        printf " [+] Open Ports: %s\n" "$ports"
        printf " [+] Unique Services: %s\n" "$unique"
        printf " [+] Top Ports: %s\n" "${top%, }"
    else
        printf "[WRN] Naabu completed, but no information was returned.\n"
        return 0
    fi

    # Create a cleartext file for input
    jq -r '.host + ":" + (.port | tostring)' "$naabu_out_json" 2>/dev/null > "$naabu_out"
}

# Run HTTPX
run_httpx() {
    local options=("Quick Discovery (Fast Triage)" "Technology Fingerprinting" "Deep Enumeration (Comprehensive)" "Screenshot & Hash (Visual Analysis)")
    options+=( "Custom Headers & Paths (Attack Surface)" "Stealth Mode (Low Noise)" "Too Much Options (go for Default)")

    printf "\n[INF] Setting up httpX\n"
    printf " [+] Gather metadata about hosts and ports.\n"
    printf "\n[WRN] This tool runs a ACTIVE and NOISY scan.\n"
   
    local PS3="[!] Select the option that fits you best: "
    while true; do
        select opt in "${options[@]}"; do
            case $opt in
                "Quick Discovery (Fast Triage)")
                    local flags=(-silent -status-code -title -content-length -follow-redirects -location -mc 200,201,204,301,302,307,308,401,403,405)
                    flags+=( -json -o "$httpx_out_json")
                    printf "\n[INF] You choose: Quick Discovery (Fast Triage)\n"
                    break
                    ;;
                "Technology Fingerprinting")
                    local flags=(-silent -status-code -title -tech-detect -server -content-type -follow-redirects -json -o "$httpx_out_json")
                    printf "\n[INF] You choose: Technology Fingerprinting\n"
                    break
                    ;;
                "Deep Enumeration (Comprehensive)")
                    local flags=(-silent -status-code -title -content-length -tech-detect -server -method -websocket -ip -cname -cdn -location)
                    flags+=( -follow-redirects -response-time -json -threads 50 -rate-limit 150 -o "$httpx_out_json")
                    printf "\n[INF] You choose: Deep Enumeration (Comprehensive)\n"
                    break
                    ;;
                "Screenshot & Hash (Visual Analysis)")
                    local flags=(-silent -status-code -title -screenshot -favicon -hash md5 -follow-redirects -json -o "$httpx_out_json")
                    printf "\n[INF] You choose: Screenshot & Hash (Visual Analysis)\n"
                    break
                    ;;
                "Custom Headers & Paths (Attack Surface)")
                    local flags=(-silent -status-code -title -path /admin,/api,/graphql,/.git,/debug -header "User-Agent: Mozilla/5.0" -follow-redirects)
                    flags+=( -mc 200,403,401,500 -json -o "$httpx_out_json")
                    printf "\n[INF] You choose: Custom Headers & Paths (Attack Surface)\n"
                    break
                    ;;
                "Stealth Mode (Low Noise)")
                    local flags=(-status-code -title -follow-redirects -random-agent -rate-limit 50 -threads 10 -timeout 10 -retries 1 -no-color)
                    flags+=( -silent -json -o "$httpx_out_json")
                    printf "\n[INF] You choose: Stealth Mode (Low Noise)\n"
                    break
                    ;;
                "Too Much Options (go for Default)")
                    local flags=(-silent -status-code -title -content-length -tech-detect -server -follow-redirects )
                    flags+=(-location -response-time -random-agent -mc 200,201,204,301,302,307,308,401,403,405 )
                    flags+=(-threads 25 -rate-limit 100 -json -o "$httpx_out_json")
                    printf "\n[INF] You choose: Information overload (Going for defaults)\n"
                    break
                    ;;
                *) echo "Invalid choice $REPLY"
                    continue
                    ;;
            esac
        done    
        printf "\n [!] Please select Confirm to continue\n"
        read -e -r -p "[OPT] Confirm (c) Select another option (s): " choice
        if [[ "$choice" =~ ^[cC]$ ]]; then
            break
        else
            continue
        fi
    done

    printf "\n###############################################################\n"
    printf "#####################   Starting HttpX    #####################\n"
    printf "###############################################################\n"

    httpx "${flags[@]}" < "$naabu_out" &> /dev/null

    if [[ $? -eq 0 && -s "$httpx_out_json" ]]; then
    local total=$(jq -s 'if type == "array" then length else 1 end' "$httpx_out_json" 2>/dev/null || echo "0")
    local success=$(jq -s '[.[] | select(.status_code == 200)] | length' "$httpx_out_json" 2>/dev/null || echo "0")
    local titles=$(jq -s '[.[] | select(.title != null and .title != "")] | length' "$httpx_out_json" 2>/dev/null || echo "0")
    local top_codes=$(jq -sr 'group_by(.status_code) | map({code: .[0].status_code, count: length}) | sort_by(-.count)[0:3] | map("\(.code) (\(.count))") | join(", ")' "$httpx_out_json" 2>/dev/null || echo "N/A")

    printf "[INF] HttpX done.\n"
    printf " [+] URLs Processed     : %s\n"  "$total"
    printf " [+] Success (200)      : %s\n" "$success"
    printf " [+] Pages with Titles  : %s\n" "$titles"
    printf " [+] Top Status Codes   : %s\n" "$top_codes"
    else
        printf "[WRN] HttpX Completed, but no information was returned.\n"
        return 0
    fi

    # Create a cleartext, sorted file for input
    jq -r '.url' "$httpx_out_json" 2>/dev/null | sort -u > "$httpx_sorted"
}

# Run URLFinder
run_urlfinder() {
    local flags=(-silent -timeout 10 -rate-limit 50 -jsonl -o "$urlfinder_out_json")

    printf "\n[INF] Setting up URLFinder.\n"
    printf " [+] Simplify and accelerate web asset discovery.\n"
    printf "\n[INF] This tool will run a passive scan.\n"

    printf "\n###############################################################\n"
    printf "#####################  Starting URLFinder  ####################\n"
    printf "###############################################################\n"

    urlfinder "${flags[@]}" < "$httpx_sorted" &> /dev/null
    
    if [[ $? -eq 0 && -s "$urlfinder_out_json" ]]; then
    local js=$(jq -s '[.[] | select(.url | test("\\.js(\\?|$)"))] | length' "$urlfinder_out_json" 2>/dev/null)
    local params=$(jq -s '[.[] | select(.url | contains("?"))] | length' "$urlfinder_out_json" 2>/dev/null)
    local interesting=$(jq -s '[.[] | select(.url | test("\\.(json|xml|yaml|env|config|bak|sql|log)"))] | length' "$urlfinder_out_json" 2>/dev/null)

    printf "[INF] URLFinder done.\n"
    printf " [+] JavaScript Files   : %s\n" "$js"
    printf " [+] URLs with Params   : %s\n" "$params"
    printf " [+] Interesting Files  : %s\n" "$interesting"
    else
        printf "[WRN] URLFinder completed, but no information was returned.\n"
        return 0
    fi

    # Clean output for httpx later
    jq -r '.url' "$urlfinder_out_json" 2>/dev/null > "$urlfinder_out"
 }

# Run Katana
run_katana() {
    local header="${output_dir}/auth_header.txt"
    local flags=()
    local auth_available=false
    local options=("Fast Crawl (breadth-first, unauthenticated)" "Deep JS Analysis (authenticated if available)" )
    options+=("Session-Based Crawl (requires auth)" "Skip")

    printf "\n[INF] Setting up Katana.\n"
    printf " [+] Crawl websites to discover endpoints, JavaScript files, and other content.\n"
    printf "\n[WRN] This tool runs a ACTIVE and NOISY scan.\n"

    if [[ -f "$header" && -s "$header" ]]; then
        auth_header=$(head -n 1 "$header")
        auth_available=true
        printf "[INF] Auth header found, authenticated modes available.\n"
    else
        printf "[WRN] No auth header found. To enable authenticated modes:\n"
        printf "  1. Log into the target and copy your session/auth header\n"
        printf "  2. Save it as a single line in: %s\n" "$header"
        printf "  3. Re-run this step\n"
        printf "  Continuing with unauthenticated modes only.\n"
    fi

    local PS3=" [!] Please select an option: "
    select opt in "${options[@]}"; do
        case $opt in
            "Fast Crawl (breadth-first, unauthenticated)")                
                flags=(-jc -jsl -kf robotstxt -kf sitemapxml -d 3 -c 20 -p 100 -aff -ef css,png,jpg,jpeg,gif,svg,ico,woff,woff2 -silent)
                flags+=( -jsonl -o "$katana_out_json")
                printf "\n[INF] You choose: Fast Endpoint Discovery (Breadth)\n"
                break 
                ;;
            "Deep JS Analysis (authenticated if available)")
                if [[ "$auth_available" == true ]]; then    
                    local auth_header=$(head -n 1 "$header")
                    flags=(-jc -jsl -xhr -aff -d 5 -js-crawl -automatic-form-fill -form-extraction -field-scope "$domain")
                    flags+=( -c 10 -p 50 -H \""$auth_header"\" -silent -jsonl -o "$katana_out_json")
                else
                    printf "[WRN] Running unauthenticated, results may be limited.\n"
                    flags=(-jc -jsl -xhr -aff -d 5 -js-crawl -automatic-form-fill -form-extraction -field-scope "$domain" -c 10 -p 50)
                    flags+=( -silent -jsonl -o "$katana_out_json")
                fi
                break
                ;;
            "Session-Based Crawl (requires auth)")
                if [[ "$auth_available" == false ]]; then
                    printf "[ERR] This mode requires auth_header.txt. Place it in %s and re-run.\n" "$output_dir"
                    continue
                fi
                local auth_header=$( head -n 1 "$header")
                flags=(-jc -jsl -d 4 -xhr -aff -kf all -automatic-form-fill -H \""$auth_header"\" -known-files all)
                flags+=( -field-scope "$domain" -c 15 -p 75 -silent -jsonl -o "$katana_out_json")
                break
                ;;
            "Skip")
                printf "\n [INF] Skipping Katana.\n"
                return 0
                ;;
            *) echo "Invalid choice $REPLY"
               continue
               ;;
        esac
    done

    if [[ ${#flags[@]} -eq 0 ]]; then
        printf "[WRN] No scan configuration selected. Skipping Katana.\n"
        return 0
    fi

    printf "\n###############################################################\n"
    printf "#####################   Starting Katana   #####################\n"
    printf "###############################################################\n"

    katana "${flags[@]}" < "$httpx_sorted" &> /dev/null

    if [[ $? -eq 0 && -s "$katana_out_json" ]]; then
        local total=$(jq -s 'length' "$katana_out_json" 2>/dev/null)
        local js=$(jq -s '[.[] | select(.request.endpoint | test("\\.js$|\\.mjs$"; "i"))] | length' "$katana_out_json" 2>/dev/null)
        local params_urls=$(jq -s '[.[] | select(.request.endpoint | contains("?"))] | length' "$katana_out_json" 2>/dev/null)
        local params_percent=$(awk "BEGIN {if ($total > 0) printf \"%.1f\", ($params_urls / $total) * 100; else print \"0.0\"}" 2>/dev/null)
        local ext=$(jq -rs '[.[] | .request.endpoint | split("?")[0]] | .[]' "$katana_out_json" | grep -oE '\.[a-zA-Z0-9]+$' | awk 'NF {a[$0]++} END {for (i in a) print a[i], i}' 2>/dev/null | sort -nr | head -3 | awk '{printf ".%s (%s), ", $2, $1}' | sed 's/, $//')
        local samples=$(jq -rs '.[] | .request.endpoint' "$katana_out_json" 2>/dev/null | grep -E '\?|/admin|/api/|/debug|/config|/backup|token=|key=|pass=|secret=|id=' | head -3 | sed 's/^/  - /')

        printf "[INF] Katana done.\n"
        printf "[+] Total endpoints     : %s\n" "$total"
        printf "[+] JavaScript Files    : %s\n" "$js"
        printf "[+] URLs with Params    : %s (%s%%)\n" "$params_urls" "$params_percent"
        printf "[+] Interesting extensions (top 3): %s\n" "${ext:-none}"
        printf "[+] Sample:\n%s\n" "${samples:-  - (none found)}"
    else
        printf "[WRN] Katana Completed, but no information was returned.\n"
        return 0
    fi

    # Clean output for httpx later
    jq -r '.request.endpoint' "$katana_out_json" 2>/dev/null > "$katana_out"
}

rerun_httpx() {

    local flags=(-status-code -title -content-length -follow-redirects -location -mc 200,201,204,301,302,307,308,401,403,405)
    flags+=( -random-agent -rate-limit 100 -threads 25 -timeout 10 -retries 1 -silent -no-color -json -o "$httpx_2ndrun_out_json")

    # Clean, combine, and sort URLFinder + Katana output.
    if [[ ! -f "$urlfinder_out" ]] || [[ ! -s "$urlfinder_out" ]]; then
        jq -r '.url' "$urlfinder_out_json" 2>/dev/null > "$urlfinder_out"
    fi
    if [[ ! -f "$katana_out" ]] || [[ ! -s "$katana_out" ]]; then
        jq -r '.request.endpoint' "$katana_out_json" 2>/dev/null > "$katana_out"
    fi
    if [[ -f "$urlfinder_out" ]] && [[ -f "$katana_out" ]]; then
        cat "$urlfinder_out" "$katana_out" | sort -u 2>/dev/null > "$httpx_final_in"
    fi

    printf "\n[INF] Setting up httpX\n"
    printf " [+] httpX will run once again to filter out any dead URLs and present cleaner and actionable data.\n"
    printf " [+] httpX flags will be set up to be more conservative this time.\n"
    printf "\n[WRN] This tool will run an ACTIVE and NOISY scan.\n"
    printf " [!] Please select Confirm to continue\n"


    while true; do
    read -e -r -p "[OPT] Confirm (c) Skip step (s): " choice
        if [[ "$choice" =~ ^[cC]$ ]]; then
            break
        elif [[ "$choice" =~ ^[sS]$ ]]; then
            printf "[INF] Skipping Httpx.\n\n"
            return 0
        else
            printf "[ERR] Wrong option.\n"
            continue
        fi
    done


    printf "\n###############################################################\n"
    printf "#####################   Starting HttpX    #####################\n"
    printf "###############################################################\n"

    httpx "${flags[@]}" < "$httpx_final_in" &> /dev/null

    if [[ $? -eq 0 && -s "$httpx_2ndrun_out_json" ]]; then
    local total=$(jq -s 'length' "$httpx_2ndrun_out_json" 2>/dev/null)
    local success=$(jq -s '[.[] | select(.status_code == 200)] | length' "$httpx_2ndrun_out_json" 2>/dev/null || echo "0")
    local titles=$(jq -s '[.[] | select(.title != null and .title != "")] | length' "$httpx_2ndrun_out_json" 2>/dev/null || echo "0")
    local top_codes=$(jq -sr 'group_by(.status_code) | map({code: .[0].status_code, count: length}) | sort_by(-.count)[0:3] | map("\(.code) (\(.count))") | join(", ")' "$httpx_2ndrun_out_json" 2>/dev/null || echo "N/A")

    printf "[INF] HttpX done.\n"
    printf " [+] URLs Processed     : %s\n"  "$total"
    printf " [+] Success (200)      : %s\n" "$success"
    printf " [+] Pages with Titles  : %s\n" "$titles"
    printf " [+] Top Status Codes   : %s\n" "$top_codes"
    else
        printf "[WRN] HttpX Completed, but no information was returned.\n"
        return 0
    fi
} 
 
# Generate report
generate_report() {
    local scan_date=$(date "+%Y-%m-%d %H:%M")

    printf "\n[INF] Generating final report.\n"

    cat << EOF > "$report_file"
# Recon Report - $domain
**Scan Date:** $scan_date
**Output Directory:** $output_dir

---
## Executive Summary
- Total subdomains discovered: $(wc -l < "$subfinder_out" 2>/dev/null || echo 0) (Subfinder) + $(wc -l < "$shuffledns_out" 2>/dev/null || echo 0) (Shuffledns)
- Total resolved hosts: $(jq -s 'length' "$dnsx_out_json" 2>/dev/null || echo 0)
- Total alive web assets (final httpx): $(jq -s 'length' "$httpx_2ndrun_out_json" 2>/dev/null || echo 0)
- Total unique endpoints crawled: $(jq -s 'length' "$katana_out_json" 2>/dev/null || echo 0)

## 1. Asset Discovery
### Subdomains
- Subfinder: $(wc -l < "$subfinder_out" 2>/dev/null || echo 0)
- Shuffledns: $(wc -l < "$shuffledns_out" 2>/dev/null || echo 0)
- AlterX permutations: $(wc -l < "$alterx_sorted" 2>/dev/null || echo 0)

### DNS Resolution (dnsx)
$(jq -s 'length' "$dnsx_out_json" 2>/dev/null || echo 0) resolved hosts
- With A/AAAA records: $(jq -c 'select((.a | length > 0) or (.aaaa | length > 0))' "$dnsx_out_json" 2>/dev/null | wc -l || echo 0)
- With CNAME (potential takeovers): $(jq -c 'select(.cname | length > 0)' "$dnsx_out_json" 2>/dev/null | wc -l || echo 0)

### Ports (Naabu)
- Hosts with open ports: $(jq -r '.host' "$naabu_out_json" 2>/dev/null | sort -u | wc -l || echo 0)
- Unique open ports: $(jq -r '.port' "$naabu_out_json" 2>/dev/null | sort -u | wc -l || echo 0)

## 2. Web Content Discovery
### First httpx pass
- Alive URLs: $(jq -s 'length' "$httpx_out_json" 2>/dev/null || echo 0)

### URLFinder + Katana + Final httpx
- Combined unique URLs fed to final httpx: $(wc -l < "$httpx_final_in" 2>/dev/null || echo 0)
- Final alive assets: $(jq -s 'length' "$httpx_2ndrun_out_json" 2>/dev/null || echo 0)

### Katana Deep Crawl
$(cat << INNER
- Total endpoints: $(jq -s 'length' "$katana_out_json" 2>/dev/null || echo 0)
- JavaScript Files: $(jq -s '[.[] | select(.request.endpoint | test("\\.js$|\\.mjs$"; "i"))] | length' "$katana_out_json" 2>/dev/null || echo 0)
- URLs with Params: $(jq -s '[.[] | select(.request.endpoint | contains("?"))] | length' "$katana_out_json" 2>/dev/null || echo 0)
- Interesting extensions (top 3): $(jq -rs '[.[] | .request.endpoint | split("?")[0]] | .[]' "$katana_out_json" 2>/dev/null | grep -oE '\.[a-zA-Z0-9]+$' | awk 'NF {a[$0]++} END {for (i in a) print a[i], i}' | sort -nr | head -3 | awk '{printf ".%s (%s), ", $2, $1}' | sed 's/, $//' || echo "none")
INNER
)

## 3. High-Value Findings
**Potential Subdomain Takeovers (CNAMEs):**
$(jq -r 'select(.cname | length > 0) | "\(.host) â†’ \(.cname[0])"' "$dnsx_out_json" 2>/dev/null | head -10 || echo "None detected")

**High-Interest Endpoints (from Katana + Urlfinder):**
$(jq -r '.request.endpoint' "$katana_out_json" 2>/dev/null | grep -E '\?|/admin|/api/|/debug|/config|/backup|token=|key=|pass=|secret=' | head -15 || echo "None found")

## 4. File Locations
- All raw outputs: $output_dir/
- Final clean URLs: $httpx_final_in
- Full report: $report_file

## 5. Next Steps & Recommendations
- Manual review of CNAME takeovers and parameter-heavy endpoints
- Add API keys to Subfinder config for better results next run

---
Generated by Bash Recon Automation Tool
EOF

    printf "[INF] Report generated: %s\n" "$report_file"
    printf "[INF] Full scan completed successfully!\n"
}

##################
### Main Logic ###
##################

# Flags options
install_tools=()
verbose=false

while getopts ":d:i:o:vh" opt; do
    case $opt in
        d) domain="$OPTARG" ;;
        o) output_dir="$OPTARG" ;;   # optional: also allow -o for output dir
        i)
            if [[ "$OPTARG" == "tools" ]]; then
                install_tools+=("$OPTARG")
            else
                echo "[!] Invalid argument. Use [-i tools]" >&2
                exit 1
            fi
            ;;
        v) verbose=true ;;
        h)
            printf "Usage: %s [-d domain] [-o output_dir] [-i tools] [-v] [-h]\n" "$0"
            printf "  -d  Target domain (e.g. example.com). Skips interactive prompt.\n"
            printf "  -o  Output directory (default: derived from domain).\n"
            printf "  -i  Install required tools (use: -i tools).\n"
            printf "  -v  Enable verbose/trace mode.\n"
            printf "  -h  Show this help.\n"
            exit 0
            ;;
        :)
            echo "[ERR] Option -$OPTARG requires an argument." >&2
            exit 1
            ;;
        *)
            echo "[!] Usage: $0 [-d domain] [-i tools] [-v] [-h]" >&2
            exit 1
            ;;
    esac
done

shift $((OPTIND-1))

for task in "${install_tools[@]}"; do
    case "$task" in
        "tools")
            install_script_tools
            ;;

    esac
done

# Verbosity will only trace the main flow
[[ $verbose == true ]] && set -x

#### ------ Phase 1: Asset Discovery ------ ####

## Logo here
## Legal disclaimer here
## Initial instructions here

# Define domain and output directory
define_variables || { echo "[DBG] define_variables failed."; exit 1; }

printf "\n####################################################################\n"
printf "##################### Phase 1: Asset Discovery #####################\n"
printf "####################################################################\n"
printf "\n[+] Asset discovery focuses on identifying domains, subdomains, IP addresses, and open ports that can be targeted.\n"

# Perform a check before running Subfinder and continue, otherwise skip it.
if check_before_run subfinder "$subfinder_out"; then
    run_subfinder 
fi

# Perform a check before running ShuffleDNS and continue, otherwise skip it.
if check_before_run shuffledns "$shuffledns_out"; then
    run_shuffledns
fi

# Configure and run AlterX
if check_before_run alterx "$alterx_out"; then
    run_alterx
fi

# Configure and run DNSX
if check_before_run dnsx "$dnsx_out_json"; then
    run_dnsx
fi

# Configure and run Naabu
if check_before_run naabu "$naabu_out_json"; then
    run_naabu
fi

# Configure and run HTTPX
if check_before_run httpx "$httpx_out_json"; then
    run_httpx
fi

#### ------ Phase 2: Content Discovery ---- ####
printf "\n####################################################################\n"
printf "#################### Phase 2: Content Discovery ####################\n"
printf "####################################################################\n"
printf "\n[+] Content discovery focuses on gathering actionable information from identified assets, such as URLs, endpoints, and application details.\n"

# Configure and run URLFinder
if check_before_run urlfinder "$urlfinder_out_json"; then
    run_urlfinder 
fi

# Configure and run Katana
if check_before_run katana "$katana_out_json"; then
    run_katana
fi

# Feed again to httpx again to remove dead URLs
if check_before_run httpx "$httpx_2ndrun_out_json"; then
    rerun_httpx
fi

#### ------ Phase 3: Report Generation ------ ####

# Generate report
if check_before_run report "$report_file"; then
   generate_report
fi 
