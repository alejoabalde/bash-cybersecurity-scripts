#!/usr/bin/env bash

set -uo pipefail
# Note: -e was intentionally omitted. Each tool invocation is checked via conditional guards, which gives us better control over failures.

### Global settings ###
domain=""
output_dir=""
pd_tools=("subfinder" "shuffledns" "alterx" "dnsx" "naabu" "httpx" "katana" "urlfinder")

### Color definitions ###
RED='\033[31m'
GREEN='\033[32m'
YELLOW='\033[33m'
CYAN='\033[36m'
MAGENTA='\033[35m'
BOLD='\033[1m'
RESET='\033[0m'

# Strip colors if output is not a terminal
if [[ ! -t 1 ]]; then
    RED=''; GREEN=''; YELLOW=''; CYAN=''; MAGENTA=''; BOLD=''; RESET=''
fi

### Message helpers ###
inf()  { printf "${CYAN}[INF]${RESET} %s\n" "$*"; }
ok()   { printf "${GREEN}[INF]${RESET} %s\n" "$*"; }
wrn()  { printf "${YELLOW}[WRN]${RESET} %s\n" "$*"; }
err()  { printf "${RED}[ERR]${RESET} %s\n\n" "$*" >&2; }
opt()  { printf "${MAGENTA}[OPT]${RESET} %s\n" "$*"; }
bang() { printf "${YELLOW} [!]${RESET} %s\n" "$*"; }
fin()  { printf "${GREEN} [+]${RESET} %s\n" "$*"; }

### Functions ###
install_script_tools() {
    local missing_tools=()

    inf "Checking if required tools are installed..."

    for tool in "${pd_tools[@]}"; do
        command -v "$tool" &> /dev/null && inf "$tool is already installed." || missing_tools+=("$tool")
    done

    [[ ${#missing_tools[@]} -eq 0 ]] && return 0

    inf "Missing tools: ${missing_tools[*]}. Installing via PDTM..."
    local install_list
    { local IFS=,; install_list="${missing_tools[*]}"; }
    if pdtm -i "$install_list" -igp; then
        inf "All required tools were installed."
    else
        err "Failed to install required tools."
        return 1
    fi
}

# Define domain and output directory if unspecified.
define_variables() {
    if [[ -z "$domain" ]]; then
        while true; do
            read -e -r -p "[!] Please specify a domain: " domain
            if [[ -z "$domain" ]]; then
                err "Domain cannot be empty."    
            elif [[ ! "$domain" =~ ^[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$ ]]; then
                err "Invalid domain syntax. Please enter a valid domain."
            else
                break
            fi
        done
    else
        if [[ ! "$domain" =~ ^[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$ ]]; then
            err "Invalid domain provided via -d flag: $domain"
            exit 1
        fi
        inf "Using domain: $domain."
    fi
    
    local strip_protocol="${domain#*://}"
    local strip_name="${strip_protocol#www.}"
    local clean_name="${strip_name%%/*}"
    
    if [[ -z "$output_dir" ]]; then
        output_dir="$clean_name"
    fi
    
    output_dir="${output_dir%/}"
    
    if [[ "$output_dir" == *..* ]]; then
        err "Output directory path must not contain '..': $output_dir"
        exit 1
    fi

    if [[ ! -d "$output_dir" ]]; then
        mkdir -p "./$output_dir"
        inf "Created directory: $output_dir"
    else
        inf "Using existing directory: $output_dir"
    fi

    declare -g _clean_name="$clean_name"
}

setup_output_paths() {
    if [[ -z "${_clean_name:-}" ]]; then
        err "setup_output_paths called before define_variables. Aborting."
        exit 1
    fi
    local clean_name="$_clean_name"

    for tool in "${pd_tools[@]}"; do
        declare -g "${tool}_out=${output_dir}/${tool}_${clean_name}.txt"
        declare -g "${tool}_out_json=${output_dir}/${tool}_${clean_name}.json"
        declare -g "${tool}_sorted=${output_dir}/sorted_${tool}_${clean_name}.txt"
        declare -g "${tool}_sorted_json=${output_dir}/sorted_${tool}_${clean_name}.json"
    done

    declare -g "httpx_2ndrun_out_json=${output_dir}/httpx_2ndrun_${clean_name}.json"
    declare -g "httpx_final_in=${output_dir}/httpx_final_in.txt"
    declare -g "report_file=${output_dir}/report.md"
}

check_before_run() {
    local tool_name="$1"
    local tool_out="$2" 

    if [[ -f "$tool_out" && -s "$tool_out" ]]; then
        wrn "$tool_name output already exists. File: $tool_out"
        read -e -r -p "[OPT] Skip $tool_name (s), Overwrite File (o), or Backup File (b)? [S/o/b]: " choice
        
        case "$choice" in
            [sS]*)
                inf "Skipping $tool_name step."
                printf "\n"
                return 1
                ;;
            [oO]*)
                inf "Overwriting existing file..."
                printf "\n"
                return 0
                ;;
            [bB]*)
                local timestamp; timestamp=$(date +"%Y%m%d_%H%M")
                local backup_file="${tool_out}_${timestamp}.bak"
                mv "$tool_out" "$backup_file"
                inf "Moved existing results to: $backup_file"
                printf "\n"
                return 0
                ;;
            *) 
                err "Invalid option. Skipping $tool_name step."
                return 1 
                ;;
        esac
    fi
    return 0
}

run_subfinder() {
    local subfinder_flags=(-d "$domain" -all -o "$subfinder_out" -silent)
    local config_file="${HOME}/.config/subfinder/provider-config.yaml"
    
    printf "\n"
    inf "Setting up Subfinder."
    fin "Discover subdomains for a given target domain."
    inf "This tool will run a passive scan."
    inf "It is recommended to add API keys to: $config_file"
    
    read -e -r -p "[OPT] Open config file in editor before running? [y/N]: " choice
    if [[ "$choice" =~ ^[yY]$ ]]; then
        "${EDITOR:-nano}" "$config_file"
    fi

    printf "\n┌─────────────────────────────────────────────────────────────────────────────────┐\n"
    printf "                                Starting Subfinder                               \n"
    printf "└─────────────────────────────────────────────────────────────────────────────────┘\n"

    if subfinder "${subfinder_flags[@]}" &>/dev/null && [[ -s "$subfinder_out" ]]; then
        local findings
        findings=$(wc -l <"$subfinder_out")
        inf "Subfinder done - $findings subdomains saved."
    else
        wrn "Subfinder completed, but no information was returned."
        return 0
    fi
}

run_shuffledns() {
    local wordlist="${PWD}/wordlist.txt"
    local resolvers="${PWD}/resolvers.txt"
    local shuffledns_flags=(-d "$domain" -w "$wordlist" -r "$resolvers" -mode bruteforce -o "$shuffledns_out" -silent)

    printf "\n"
    inf "Setting up ShuffleDNS."
    fin "Brute-force subdomains that may not be found through passive enumeration."
    wrn "This tool runs an ACTIVE and NOISY scan."

    inf "ShuffleDNS requires a wordlist and a public DNS resolver list for best results."
    fin " Recommended sources:"
    fin "  - Trickest  (Resolvers):  https://github.com/trickest/resolvers/blob/main/resolvers.txt"
    fin "  - SecLists  (Wordlists):  https://github.com/danielmiessler/SecLists"
    fin "  - AssetNote (Wordlists):  https://wordlists.assetnote.io"
    bang "Download one and save it as resolvers.txt in your working directory."
    bang "Download one and save it as wordlist.txt in your working directory."
    bang "Please select Confirm to continue"
    
    while true; do
        read -e -r -p "[OPT] Confirm (c) Skip step (s): " add_choice
        if [[ "$add_choice" =~ ^[cC]$ ]]; then
            if [[ ! -f "$wordlist" || ! -f "$resolvers" ]]; then
                err "Missing files! Ensure both wordlist.txt and resolvers.txt exist."
                continue
            else
                break
            fi
        elif [[ "$add_choice" =~ ^[sS]$ ]]; then
            inf "Skipping step."
            return 1
        else
            err "Wrong option."
            continue
        fi
    done
    printf "\n┌─────────────────────────────────────────────────────────────────────────────────┐\n"
    printf "                               Starting ShuffleDNS                               \n"
    printf "└─────────────────────────────────────────────────────────────────────────────────┘\n"

    if shuffledns "${shuffledns_flags[@]}" &>/dev/null && [[ -s "$shuffledns_out" ]]; then
        local findings
        findings=$(wc -l < "$shuffledns_out")
        ok "ShuffleDNS done - $findings subdomains saved."
    else
        wrn "ShuffleDNS completed, but no information was returned."
        return 0
    fi
}

run_alterx() {
    local keywords_file="${PWD}/target-keywords.txt"
    local alterx_flags=("-silent" "-enrich" "-o" "$alterx_out")
    local file_input=""

    printf "\n"
    inf "Setting up AlterX."
    fin "Generate permutations of subdomains to identify additional assets."

    # Sort by uniqueness into a single file
    if [[ -s "$subfinder_out" && -s "$shuffledns_out" ]]; then
        sort -u "$subfinder_out" "$shuffledns_out" > "${output_dir}/sorted_subfinder_shuffledns.txt"
        file_input="${output_dir}/sorted_subfinder_shuffledns.txt"
    elif [[ -s "$subfinder_out" ]]; then
        wrn "ShuffleDNS results missing. Using Subfinder output only."
        file_input="$subfinder_out"
    elif [[ -s "$shuffledns_out" ]]; then
        wrn "Subfinder results missing. Using ShuffleDNS output only."
        file_input="$shuffledns_out"
    else
        err "No input files found for AlterX! Skipping."
        return 1
    fi

    # Add target keywords
    inf "It is recommended to add target-specific keywords to enhance results."
    inf "Examples: company products, acronyms, brands, language-specific terms."
    bang "Do you wish to add any?"
    
    while true; do
        read -e -r -p "[OPT] Add now (a) Skip action (s): " add_choice
        if [[ "$add_choice" =~ ^[aA]$ ]]; then
            while true; do
                bang "Create a file named target-keywords.txt containing a keyword per line."
                read -e -r -p "[OPT] Continue (c) or Skip action (s): " loop_choice
                if [[ "$loop_choice" =~ ^[cC]$ ]]; then
                    if [[ -s "$keywords_file" ]]; then
                        alterx_flags+=("-pp" "word=$keywords_file")
                        break
                    else
                        err "File target-keywords.txt not found or empty."
                    fi
                elif [[ "$loop_choice" =~ ^[sS]$ ]]; then
                    inf "Skipping action."
                    break
                else
                    err "Wrong option."
                    continue
                fi
            done
            break
        elif [[ "$add_choice" =~ ^[sS]$ ]]; then
            inf "Skipping action."
            break
        else
            err "Wrong option."
            continue
        fi
    done

    printf "\n┌─────────────────────────────────────────────────────────────────────────────────┐\n"
    printf "                                 Starting AlterX                                 \n"
    printf "└─────────────────────────────────────────────────────────────────────────────────┘\n"

    if alterx "${alterx_flags[@]}" < "$file_input" &> /dev/null && [[ -s "$alterx_out" ]]; then
        local findings
        findings=$(wc -l < "$alterx_out")
        ok "AlterX done - $findings permutations saved."
    else
        wrn "AlterX completed, but no information was returned."
        return 0
    fi

    # Final sort to prevent duplications in big scopes
    sort -u "$alterx_out" > "$alterx_sorted" 
}

run_dnsx() {
    local dnsx_flags=(-l "$alterx_sorted" -silent -a -aaaa -cname -resp-only -json -r resolvers.txt)
    dnsx_flags+=( -t 150 -retry 3 -o "$dnsx_out_json")
    
    printf "\n┌─────────────────────────────────────────────────────────────────────────────────┐\n"
    printf "                                  Starting dnsx                                  \n"
    printf "└─────────────────────────────────────────────────────────────────────────────────┘\n"

    fin "Verify which subdomains resolve to valid hosts."
    wrn "This is an ACTIVE and NOISY step."
    bang "Select Confirm to start."
    
    while true; do
        read -e -r -p "[OPT] Confirm (c) Skip step (s): " choice
        if [[ "$choice" =~ ^[cC]$ ]]; then
            printf "\n"
            inf "Starting dnsx. This will take a while."
            break
        elif [[ "$choice" =~ ^[sS]$ ]]; then
            inf "Skipping dnsx."
            return 0
        else
            err "Wrong option."
            continue
        fi
    done

    if dnsx "${dnsx_flags[@]}" &> /dev/null && [[ -s "$dnsx_out_json" ]]; then
        local resolved_hosts resolved_a_aaaa resolved_cname resolved_sample
        resolved_hosts=$(jq -c 'select(.host != null and (.a + .aaaa + .cname | length > 0))' "$dnsx_out_json" 2>/dev/null | wc -l)
        resolved_a_aaaa=$(jq -c 'select((.a | length > 0) or (.aaaa | length > 0))' "$dnsx_out_json" 2>/dev/null | wc -l)
        resolved_cname=$(jq -c 'select(.cname | length > 0)' "$dnsx_out_json" 2>/dev/null | wc -l)
        resolved_sample=$(head -n 200 "$dnsx_out_json" | jq -r '
        select(.host != null and (.a[0] != null or .aaaa[0] != null) and .cname[0] != null) | "\(.host)\t->\t\((.a[0] // .aaaa[0]))\t|\t\(.cname[0])"
        ' 2>/dev/null | head -n 5 | column -t -s $'\t' | sed 's/^/       /')

        ok "dnsx done - $resolved_hosts resolved hosts."
        fin "$resolved_a_aaaa with A/AAAA records."
        fin "$resolved_cname with CNAME (potential takeovers?)"
        fin "Sample: "
        printf "%s\n" "$resolved_sample"
    else
        wrn "dnsx completed, but no information was returned."
        return 0
    fi

    # Create a cleartext sorted file for input
    jq -r 'select((.a | length > 0) or (.aaaa | length > 0) or (.cname | length > 0)) | .host' "$dnsx_out_json" 2>/dev/null | sort -u > "$dnsx_sorted"
}

# Run Naabu
run_naabu() {
    local naabu_flags=(-top-ports 1000 -rate 1000 -c 25 -warm-up-time 2 -retries 2 -timeout 3000 -exclude-cdn -silent -stats)
    naabu_flags+=( -json -o "$naabu_out_json")
    
    printf "\n┌─────────────────────────────────────────────────────────────────────────────────┐\n"
    printf "                                  Starting naabu                                 \n"
    printf "└─────────────────────────────────────────────────────────────────────────────────┘\n"

    fin "Identify open ports on resolved hosts to find additional applications."
    wrn "This is an ACTIVE and NOISY step."
    bang "Select Confirm to start."
    
    while true; do
        read -e -r -p "[OPT] Confirm (c) Skip step (s): " choice
        if [[ "$choice" =~ ^[cC]$ ]]; then
            printf "\n"
            inf "Starting naabu. This will take a while."
            break
        elif [[ "$choice" =~ ^[sS]$ ]]; then
            inf "Skipping Naabu."
            return 1
        else
            err "Wrong option."
            continue
        fi
    done

    if naabu "${naabu_flags[@]}" < "$dnsx_sorted" &> /dev/null && [[ -s "$naabu_out_json" ]]; then
        local hosts ports unique top
        hosts=$(jq -r '.host' "$naabu_out_json" 2>/dev/null | sort -u | wc -l)
        ports=$(jq -r '.port' "$naabu_out_json" 2>/dev/null | wc -l)
        unique=$(jq -r '.port' "$naabu_out_json" 2>/dev/null | sort -u | wc -l)
        top=$(jq -r '.port' "$naabu_out_json" 2>/dev/null | sort | uniq -c | sort -rn | head -3 | awk '{printf "%s (%s), ", $2, $1}')

        ok "Naabu done."
        fin "Hosts Processed: $hosts hosts"
        fin "Open Ports: $ports"
        fin "Unique Services: $unique"
        fin "Top Ports: ${top%, }"
        printf "\n"

    else
        wrn "Naabu completed, but no information was returned."
        return 0
    fi

    # Create a cleartext file for input
    jq -r '.host + ":" + (.port | tostring)' "$naabu_out_json" 2>/dev/null > "$naabu_out"
}

# Run HTTPX
run_httpx() {
    local options=("Quick Discovery (Fast Triage)" "Technology Fingerprinting" "Deep Enumeration (Comprehensive)" "Screenshot & Hash (Visual Analysis)")
    options+=( "Custom Headers & Paths (Attack Surface)" "Stealth Mode (Low Noise)" "Too Much Options (go for Default)")

    inf "Setting up httpX."
    fin "Gather metadata about hosts and ports."
    wrn "This tool runs an ACTIVE and NOISY scan."
    printf "\n"
   
    local PS3="[!] Select the option that fits you best: "
    local flags=()
    select opt in "${options[@]}"; do
        case $opt in
            "Quick Discovery (Fast Triage)")
                flags=(-silent -status-code -title -content-length -follow-redirects -location -mc 200,201,204,301,302,307,308,401,403,405)
                flags+=( -json -o "$httpx_out_json")
                printf "\n"
                inf "You chose: Quick Discovery (Fast Triage)"
                break
                ;;
            "Technology Fingerprinting")
                flags=(-silent -status-code -title -tech-detect -server -content-type -follow-redirects -json -o "$httpx_out_json")
                printf "\n"
                inf "You chose: Technology Fingerprinting"
                break
                ;;
            "Deep Enumeration (Comprehensive)")
                flags=(-silent -status-code -title -content-length -tech-detect -server -method -websocket -ip -cname -cdn -location)
                flags+=( -follow-redirects -response-time -json -threads 50 -rate-limit 150 -o "$httpx_out_json")
                printf "\n"
                inf "You chose: Deep Enumeration (Comprehensive)"
                break
                ;;
            "Screenshot & Hash (Visual Analysis)")
                flags=(-silent -status-code -title -screenshot -favicon -hash md5 -follow-redirects -json -o "$httpx_out_json")
                printf "\n"
                inf "You chose: Screenshot & Hash (Visual Analysis)"
                break
                ;;
            "Custom Headers & Paths (Attack Surface)")
                flags=(-silent -status-code -title -path /admin,/api,/graphql,/.git,/debug -header "User-Agent: Mozilla/5.0" -follow-redirects)
                flags+=( -mc 200,403,401,500 -json -o "$httpx_out_json")
                printf "\n"
                inf "You chose: Custom Headers & Paths (Attack Surface)"
                break
                ;;
            "Stealth Mode (Low Noise)")
                flags=(-status-code -title -follow-redirects -random-agent -rate-limit 50 -threads 10 -timeout 10 -retries 1 -no-color)
                flags+=( -silent -json -o "$httpx_out_json")
                printf "\n"
                inf "You chose: Stealth Mode (Low Noise)"
                break
                ;;
            "Too Much Options (go for Default)")
                flags=(-silent -status-code -title -content-length -tech-detect -server -follow-redirects )
                flags+=(-location -response-time -random-agent -mc 200,201,204,301,302,307,308,401,403,405 )
                flags+=(-threads 25 -rate-limit 100 -json -o "$httpx_out_json")
                printf "\n"
                inf "You chose: Too Much Options (go for Default)"
                break
                ;;
            *) err "Invalid choice: $REPLY"
                continue
                ;;
        esac
    done

    printf "\n┌─────────────────────────────────────────────────────────────────────────────────┐\n"
    printf "                                  Starting HttpX                                 \n"
    printf "└─────────────────────────────────────────────────────────────────────────────────┘\n"

    if httpx "${flags[@]}" < "$naabu_out" &> /dev/null && [[ -s "$httpx_out_json" ]]; then
        local total success titles top_codes
        total=$(jq -s 'if type == "array" then length else 1 end' "$httpx_out_json" 2>/dev/null || echo "0")
        success=$(jq -s '[.[] | select(.status_code == 200)] | length' "$httpx_out_json" 2>/dev/null || echo "0")
        titles=$(jq -s '[.[] | select(.title != null and .title != "")] | length' "$httpx_out_json" 2>/dev/null || echo "0")
        top_codes=$(jq -sr 'group_by(.status_code) | map({code: .[0].status_code, count: length}) | sort_by(-.count)[0:3] | map("\(.code) (\(.count))") | join(", ")' "$httpx_out_json" 2>/dev/null || echo "N/A")

        ok "HttpX done."
        fin "URLs Processed     : $total"
        fin "Success (200)      : $success"
        fin "Pages with Titles  : $titles"
        fin "Top Status Codes   : $top_codes"
    else
        wrn "HttpX completed, but no information was returned."
        return 0
    fi

    # Create a cleartext, sorted file for input
    jq -r '.url' "$httpx_out_json" 2>/dev/null | sort -u > "$httpx_sorted"
}

# Run URLFinder
run_urlfinder() {
    local flags=(-silent -timeout 10 -rate-limit 50 -jsonl -o "$urlfinder_out_json")

    printf "\n"
    inf "Setting up URLFinder."
    fin "Simplify and accelerate web asset discovery."
    inf "This tool will run a passive scan."
    
    printf "\n┌─────────────────────────────────────────────────────────────────────────────────┐\n"
    printf "                                Starting URLFinder                               \n"
    printf "└─────────────────────────────────────────────────────────────────────────────────┘\n"

    if urlfinder "${flags[@]}" < "$httpx_sorted" &> /dev/null && [[ -s "$urlfinder_out_json" ]]; then
        local js params interesting
        js=$(jq -s '[.[] | select(.url | test("\\.js(\\?|$)"))] | length' "$urlfinder_out_json" 2>/dev/null)
        params=$(jq -s '[.[] | select(.url | contains("?"))] | length' "$urlfinder_out_json" 2>/dev/null)
        interesting=$(jq -s '[.[] | select(.url | test("\\.(json|xml|yaml|env|config|bak|sql|log)"))] | length' "$urlfinder_out_json" 2>/dev/null)

        ok "URLFinder done."
        fin "JavaScript Files   : $js"
        fin "URLs with Params   : $params"
        fin "Interesting Files  : $interesting"
    else
        wrn "URLFinder completed, but no information was returned."
        return 0
    fi

    # Clean output for httpx later
    jq -r '.url' "$urlfinder_out_json" 2>/dev/null > "$urlfinder_out"
}

# Run Katana
run_katana() {
    local header="${output_dir}/auth_header.txt"
    local flags=()
    local auth_available=false
    local auth_header=""
    local options=("Fast Crawl (breadth-first, unauthenticated)" "Deep JS Analysis (authenticated if available)" )
    options+=("Session-Based Crawl (requires auth)" "Skip")

    printf "\n"
    inf "Setting up Katana."
    fin "Crawl websites to discover endpoints, JavaScript files, and other content."
    wrn "This tool runs an ACTIVE and NOISY scan."

    if [[ -f "$header" && -s "$header" ]]; then
        auth_header=$(head -n 1 "$header")
        auth_available=true
        inf "Auth header found, authenticated modes available."
        printf "\n"
    else
        wrn "No auth header found. To enable authenticated modes:"
        inf "  1. Log into the target and copy your session/auth header"
        inf "  2. Save it as a single line in: $header"
        inf "  3. Re-run this step"
        inf "  Continuing with unauthenticated modes only."
        printf "\n"
    fi

    local PS3="[!] Please select an option: "
    select opt in "${options[@]}"; do
        case $opt in
            "Fast Crawl (breadth-first, unauthenticated)")                
                flags=(-jc -jsl -kf robotstxt -kf sitemapxml -d 3 -c 20 -p 100 -aff -ef css,png,jpg,jpeg,gif,svg,ico,woff,woff2 -silent)
                flags+=( -jsonl -o "$katana_out_json")
                printf "\n"
                inf "You chose: Fast Endpoint Discovery (Breadth)"
                break 
                ;;
            "Deep JS Analysis (authenticated if available)")
                if [[ "$auth_available" == true ]]; then    
                    printf "\n"
                    inf "You chose: Deep JS Analysis (authenticated)"
                    auth_header=$(head -n 1 "$header")
                    flags=(-jc -jsl -xhr -aff -d 5 -js-crawl -automatic-form-fill -form-extraction -field-scope "$domain")
                    flags+=( -c 10 -p 50 -H "$auth_header" -silent -jsonl -o "$katana_out_json")

                else
                    printf "\n"
                    inf "You chose: Deep JS Analysis"
                    wrn "Running unauthenticated, results may be limited."
                    flags=(-jc -jsl -xhr -aff -d 5 -js-crawl -automatic-form-fill -form-extraction -field-scope "$domain" -c 10 -p 50)
                    flags+=( -silent -jsonl -o "$katana_out_json")
                fi
                break
                ;;
            "Session-Based Crawl (requires auth)")
                if [[ "$auth_available" == false ]]; then
                    err "This mode requires auth_header.txt. Place it in $output_dir and re-run."
                    continue
                fi
                printf "\n"
                inf "You chose: Session-Based Crawl (Authenticated)"
                auth_header=$(head -n 1 "$header")
                flags=(-jc -jsl -d 4 -xhr -aff -kf all -automatic-form-fill -H "$auth_header" -known-files all)
                flags+=( -field-scope "$domain" -c 15 -p 75 -silent -jsonl -o "$katana_out_json")
                break
                ;;
            "Skip")
                inf "Skipping Katana."
                return 0
                ;;
            *) err "Invalid choice: $REPLY"
               continue
               ;;
        esac
    done

    if [[ ${#flags[@]} -eq 0 ]]; then
        wrn "No scan configuration selected. Skipping Katana."
        return 0
    fi

    printf "\n┌─────────────────────────────────────────────────────────────────────────────────┐\n"
    printf "                                 Starting Katana                                 \n"
    printf "└─────────────────────────────────────────────────────────────────────────────────┘\n"

    if katana "${flags[@]}" < "$httpx_sorted" &> /dev/null && [[ -s "$katana_out_json" ]]; then
        local total js params_urls params_percent ext samples
        total=$(jq -s 'length' "$katana_out_json" 2>/dev/null)
        js=$(jq -s '[.[] | select(.request.endpoint | test("\\.js$|\\.mjs$"; "i"))] | length' "$katana_out_json" 2>/dev/null)
        params_urls=$(jq -s '[.[] | select(.request.endpoint | contains("?"))] | length' "$katana_out_json" 2>/dev/null)
        params_percent=$(awk "BEGIN {if ($total > 0) printf \"%.1f\", ($params_urls / $total) * 100; else print \"0.0\"}" 2>/dev/null)
        ext=$(jq -rs '[.[] | .request.endpoint | split("?")[0]] | .[]' "$katana_out_json" | grep -oE '\.[a-zA-Z0-9]+$' | awk 'NF {a[$0]++} END {for (i in a) print a[i], i}' 2>/dev/null | sort -nr | head -3 | awk '{printf ".%s (%s), ", $2, $1}' | sed 's/, $//')
        samples=$(jq -rs '.[] | .request.endpoint' "$katana_out_json" 2>/dev/null | grep -E '\?|/admin|/api/|/debug|/config|/backup|token=|key=|pass=|secret=|id=' | head -3 | sed 's/^/  - /')

        ok "Katana done."
        fin "Total endpoints     : $total"
        fin "JavaScript Files    : $js"
        fin "URLs with Params    : $params_urls ($params_percent%)"
        fin "Interesting extensions (top 3): ${ext:-none}"
        fin "Sample: "
        printf "%s\n" "${samples:-  - (none found)}"
    else
        wrn "Katana completed, but no information was returned."
        printf "\n"
        return 0
    fi

    # Clean output for httpx later
    jq -r '.request.endpoint' "$katana_out_json" 2>/dev/null > "$katana_out"
}

rerun_httpx() {

    local flags=(-status-code -title -content-length -follow-redirects -location -mc 200,201,204,301,302,307,308,401,403,405)
    flags+=( -random-agent -rate-limit 100 -threads 25 -timeout 10 -retries 1 -silent -no-color -json -o "$httpx_2ndrun_out_json")

    # Clean, combine, and sort URLFinder + Katana output.
    if [[ ! -f "$urlfinder_out" ]] || [[ ! -s "$urlfinder_out" ]]; then
        jq -r '.url' "$urlfinder_out_json" 2>/dev/null > "$urlfinder_out"
    fi
    if [[ ! -f "$katana_out" ]] || [[ ! -s "$katana_out" ]]; then
        jq -r '.request.endpoint' "$katana_out_json" 2>/dev/null > "$katana_out"
    fi
    if [[ -f "$urlfinder_out" ]] && [[ -f "$katana_out" ]]; then
        sort -u "$urlfinder_out" "$katana_out" > "$httpx_final_in"
    fi

    inf "Setting up httpX (second pass)."
    wrn "This tool will run an ACTIVE and NOISY scan."
    printf "\n"
    inf "Notice:"
    fin "httpX will run once again to filter out dead URLs and present cleaner, actionable data."
    fin "httpX flags will be set up to be more conservative this time."
    bang "Please select Confirm to continue"

    while true; do
        read -e -r -p "[OPT] Confirm (c) Skip step (s): " choice
        if [[ "$choice" =~ ^[cC]$ ]]; then
            break
        elif [[ "$choice" =~ ^[sS]$ ]]; then
            inf "Skipping httpX."
            return 0
        else
            err "Wrong option."
            continue
        fi
    done

    printf "\n┌─────────────────────────────────────────────────────────────────────────────────┐\n"
    printf "                                  Starting HttpX                                 \n"
    printf "└─────────────────────────────────────────────────────────────────────────────────┘\n"

    if httpx "${flags[@]}" < "$httpx_final_in" &> /dev/null && [[ -s "$httpx_2ndrun_out_json" ]]; then
        local total success titles top_codes
        total=$(jq -s 'length' "$httpx_2ndrun_out_json" 2>/dev/null)
        success=$(jq -s '[.[] | select(.status_code == 200)] | length' "$httpx_2ndrun_out_json" 2>/dev/null || echo "0")
        titles=$(jq -s '[.[] | select(.title != null and .title != "")] | length' "$httpx_2ndrun_out_json" 2>/dev/null || echo "0")
        top_codes=$(jq -sr 'group_by(.status_code) | map({code: .[0].status_code, count: length}) | sort_by(-.count)[0:3] | map("\(.code) (\(.count))") | join(", ")' "$httpx_2ndrun_out_json" 2>/dev/null || echo "N/A")

        ok "HttpX done."
        fin "URLs Processed     : $total"
        fin "Success (200)      : $success"
        fin "Pages with Titles  : $titles"
        fin "Top Status Codes   : $top_codes"
    else
        wrn "HttpX completed, but no information was returned."
        return 0
    fi
} 

# Generate report
generate_report() {
    local scan_date
    scan_date=$(date "+%Y-%m-%d %H:%M")

    inf "Generating final report."

    cat << EOF > "$report_file"
# Recon Report - $domain
**Scan Date:** $scan_date
**Output Directory:** $output_dir

---
## Executive Summary
- Total subdomains discovered: $(wc -l < "$subfinder_out" 2>/dev/null) (Subfinder) + $(wc -l < "$shuffledns_out" 2>/dev/null) (Shuffledns)
- Total resolved hosts: $(jq -s 'length' "$dnsx_out_json" 2>/dev/null)
- Total alive web assets (final httpx): $(jq -s 'length' "$httpx_2ndrun_out_json" 2>/dev/null)
- Total unique endpoints crawled: $(jq -s 'length' "$katana_out_json" 2>/dev/null)

## 1. Asset Discovery
### Subdomains
- Subfinder: $(wc -l < "$subfinder_out" 2>/dev/null)
- Shuffledns: $(wc -l < "$shuffledns_out" 2>/dev/null)
- AlterX permutations: $(wc -l < "$alterx_sorted" 2>/dev/null)

### DNS Resolution (dnsx)
$(jq -s 'length' "$dnsx_out_json" 2>/dev/null) resolved hosts
- With A/AAAA records: $(jq -c 'select((.a | length > 0) or (.aaaa | length > 0))' "$dnsx_out_json" 2>/dev/null | wc -l)
- With CNAME (potential takeovers): $(jq -c 'select(.cname | length > 0)' "$dnsx_out_json" 2>/dev/null | wc -l)

### Ports (Naabu)
- Hosts with open ports: $(jq -r '.host' "$naabu_out_json" 2>/dev/null | sort -u | wc -l)
- Unique open ports: $(jq -r '.port' "$naabu_out_json" 2>/dev/null | sort -u | wc -l)

## 2. Web Content Discovery
### First httpx pass
- Alive URLs: $(jq -s 'length' "$httpx_out_json" 2>/dev/null)

### URLFinder + Katana + Final httpx
- Combined unique URLs fed to final httpx: $(wc -l < "$httpx_final_in" 2>/dev/null)
- Final alive assets: $(jq -s 'length' "$httpx_2ndrun_out_json" 2>/dev/null)

### Katana Deep Crawl
$(cat << INNER
- Total endpoints: $(jq -s 'length' "$katana_out_json" 2>/dev/null)
- JavaScript Files: $(jq -s '[.[] | select(.request.endpoint | test("\\.js$|\\.mjs$"; "i"))] | length' "$katana_out_json" 2>/dev/null)
- URLs with Params: $(jq -s '[.[] | select(.request.endpoint | contains("?"))] | length' "$katana_out_json" 2>/dev/null)
- Interesting extensions (top 3): $(jq -rs '[.[] | .request.endpoint | split("?")[0]] | .[]' "$katana_out_json" 2>/dev/null | grep -oE '\.[a-zA-Z0-9]+$' | awk 'NF {a[$0]++} END {for (i in a) print a[i], i}' | sort -nr | head -3 | awk '{printf "%s (%s), ", $2, $1}' | sed 's/, $//')
INNER
)

## 3. High-Value Findings
**Potential Subdomain Takeovers (CNAMEs):**
$(jq -r 'select(.cname | length > 0) | "\(.host) → \(.cname[0])"' "$dnsx_out_json" 2>/dev/null | head -10)

**High-Interest Endpoints (from Katana + Urlfinder):**
$(jq -r '.request.endpoint' "$katana_out_json" 2>/dev/null | grep -E '\?|/admin|/api/|/debug|/config|/backup|token=|key=|pass=|secret=' | head -15)

## 4. File Locations
- All raw outputs: $output_dir/
- Final clean URLs: $httpx_final_in
- Full report: $report_file

## 5. Next Steps & Recommendations
- Manual review of CNAME takeovers and parameter-heavy endpoints
- Add API keys to Subfinder config for better results next run

---
Generated by TangoRecon automation Tool
EOF

    ok "Report generated: $report_file"
    ok "Full scan completed successfully!"
}

print_logo() {
    printf '\033[1;32m'
    cat << 'EOF'
      _____                        ____
     |_   _|_ _ _ __   __ _  ___  |  _ \ ___  ___ ___  _ __
       | |/ _` | '_ \ / _` |/ _ \ | |_) / _ \/ __/ _ \| '_ \
       | | (_| | | | | (_| | (_) ||  _ <  __/ (_| (_) | | | |
       |_|\__,_|_| |_|\__, |\___/ |_| \_\___|\___\___/|_| |_|
                      |___/
                                              TangoRecon v1.0
EOF
    printf '\033[0m'
}

### Main Logic ###

# Flags options
install_tools=()
verbose=false

while getopts ":d:i:o:vh" opt; do
    case $opt in
        d) domain="$OPTARG" ;;
        o) output_dir="$OPTARG" ;;
        i)
            if [[ "$OPTARG" == "tools" ]]; then
                install_tools+=("$OPTARG")
            else
                echo "[!] Invalid argument. Use [-i tools]" >&2
                exit 1
            fi
            ;;
        v) verbose=true ;;
        h)
            printf "Usage: %s [-d domain] [-o output_dir] [-i tools] [-v] [-h]\n" "$0"
            printf "  -d  Target domain (e.g. example.com). Skips interactive prompt.\n"
            printf "  -o  Output directory (default: derived from domain).\n"
            printf "  -i  Install required tools (use: -i tools).\n"
            printf "  -v  Enable verbose/trace mode.\n"
            printf "  -h  Show this help.\n"
            exit 0
            ;;
        :)
            echo "[ERR] Option -$OPTARG requires an argument." >&2
            exit 1
            ;;
        *)
            echo "[!] Usage: $0 [-d domain] [-i tools] [-v] [-h]" >&2
            exit 1
            ;;
    esac
done

shift $((OPTIND-1))

for task in "${install_tools[@]}"; do
    case "$task" in
        "tools")
            install_script_tools
            ;;

    esac
done

# Verbosity will only trace the main flow
[[ $verbose == true ]] && set -x

##################################
#### Phase 1: Asset Discovery ####
##################################

## Legal disclaimer
printf "\n"
printf "═════════════════════════════════════════════════════════════════════════════════\n"
printf "═════ WARNING - LEGAL & ETHICAL USE ONLY ════════════════════════════════════════\n"
printf "This tool is intended STRICTLY for authorized security testing:\n"
printf "  - Bug bounty programs with explicit in-scope permission\n"
printf "  - Assets you own or have written permission to test\n"
printf "  - Internal red/purple team exercises with approval\n"
printf "Use of this script is at your own risk. The author is not responsible for misuse.\n"
printf "═════════════════════════════════════════════════════════════════════════════════\n\n"

print_logo                                                                          

# Define domain and output directory
define_variables || { echo "[DBG] define_variables failed."; exit 1; }

# Set up all output path globals now that output_dir and _clean_name are known
setup_output_paths

printf "\n┌─────────────────────────────────────────────────────────────────────────────────┐\n"
printf "                             Phase 1: Asset Discovery                            \n"
printf "└─────────────────────────────────────────────────────────────────────────────────┘\n"
fin "Enumerating subdomains, hosts, and open ports..."

# Perform a check before running Subfinder and continue, otherwise skip it.
if check_before_run subfinder "$subfinder_out"; then
    run_subfinder 
fi

# Perform a check before running ShuffleDNS and continue, otherwise skip it.
if check_before_run shuffledns "$shuffledns_out"; then
    run_shuffledns
fi

# Configure and run AlterX
if check_before_run alterx "$alterx_out"; then
    run_alterx
fi

# Configure and run DNSX
if check_before_run dnsx "$dnsx_out_json"; then
    run_dnsx
fi

# Configure and run Naabu
if check_before_run naabu "$naabu_out_json"; then
    run_naabu
fi

# Configure and run HTTPX
if check_before_run httpx "$httpx_out_json"; then
    run_httpx
fi

printf "\n┌─────────────────────────────────────────────────────────────────────────────────┐\n"
printf "                            Phase 2: Content Discovery                           \n"
printf "└─────────────────────────────────────────────────────────────────────────────────┘\n"
fin "Gather actionable data from identified assets."
printf "\n"

# Configure and run URLFinder
if check_before_run urlfinder "$urlfinder_out_json"; then
    run_urlfinder 
fi

# Configure and run Katana
if check_before_run katana "$katana_out_json"; then
    run_katana
fi

# Feed URLs back into httpx to remove dead ones
if check_before_run httpx "$httpx_2ndrun_out_json"; then
    rerun_httpx
fi

# Generate report
if check_before_run report "$report_file"; then
   generate_report
fi 
